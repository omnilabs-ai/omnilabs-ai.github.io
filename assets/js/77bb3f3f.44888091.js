"use strict";(self.webpackChunkomnidocs=self.webpackChunkomnidocs||[]).push([[733],{2389:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"endpoints/fetch-models","title":"\ud83d\udccc Fetch Available Models","description":"Endpoints: /v1/models/chat, /v1/models/image","source":"@site/docs/endpoints/fetch-models.md","sourceDirName":"endpoints","slug":"/endpoints/fetch-models","permalink":"/docs/endpoints/fetch-models","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/endpoints/fetch-models.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Endpoints","permalink":"/docs/category/endpoints"},"next":{"title":"\ud83d\udde8\ufe0f Chat Completions","permalink":"/docs/endpoints/chat-completions"}}');var t=s(4848),r=s(8453);const l={sidebar_position:1},o="\ud83d\udccc Fetch Available Models",a={},d=[{value:"\ud83d\udcdd Usage",id:"-usage",level:4},{value:"\ud83d\udd39 Parameters",id:"-parameters",level:4},{value:"\ud83d\udd39 Response Example",id:"-response-example",level:4},{value:"\ud83d\udccb Supported Chat Models",id:"-supported-chat-models",level:4}];function c(e){const n={code:"code",h1:"h1",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"-fetch-available-models",children:"\ud83d\udccc Fetch Available Models"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Endpoints:"})," ",(0,t.jsx)(n.code,{children:"/v1/models/chat"}),", ",(0,t.jsx)(n.code,{children:"/v1/models/image"})]}),"\n",(0,t.jsx)(n.p,{children:"This functionality allows you to query the API for a list of all supported models. You can filter by model type (chat or image)."}),"\n",(0,t.jsx)(n.h4,{id:"-usage",children:"\ud83d\udcdd Usage"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"all_models = client.get_available_models()\r\nchat_models = client.get_available_models(model_type='chat')\r\nimage_models = client.get_available_models(model_type='image')\n"})}),"\n",(0,t.jsx)(n.h4,{id:"-parameters",children:"\ud83d\udd39 Parameters"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Parameter"}),(0,t.jsx)(n.th,{children:"Type"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsx)(n.tbody,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"model_type"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"str"})}),(0,t.jsxs)(n.td,{children:["Filter by 'chat' or 'image' models. If ",(0,t.jsx)(n.code,{children:"None"}),", returns all models."]})]})})]}),"\n",(0,t.jsx)(n.h4,{id:"-response-example",children:"\ud83d\udd39 Response Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'[\r\n    "gpt-4": {\r\n        name="gpt-4",\r\n        provider="openai",\r\n        description=(\r\n            "OpenAI\'s flagship model excelling in complex reasoning and coding. "\r\n            "Strengths: Technical explanations, API integrations, and multi-step problem solving. "\r\n            "Weaknesses: Higher cost, slower response times. Hallucination rate 40% higher than GPT-4o"\r\n        ),\r\n        max_tokens=8192,\r\n        benchmarks={\r\n            "MMLU": 0.864,\r\n            "GPQA": 0.414,\r\n            "HumanEval": 0.866,\r\n            "MATH": 0.529,\r\n            "BFCL": 0.883,\r\n            "MGSM": 0.86\r\n        },\r\n        cost_per_million_tokens=30.0,  # cost in USD\r\n        latency=1.1          # tokens per second\r\n    },\r\n    "claude-3-5-sonnet": ModelInfo(\r\n        name="claude-3-5-sonnet-20241022",\r\n        provider="anthropic",\r\n        description=(\r\n            "Claude 3.5 Sonnet is Anthropic\'s first release in the forthcoming Claude 3.5 model family. Claude 3.5 Sonnet raises the industry bar for intelligence, outperforming competitor models and Claude 3 Opus on a wide range of evaluations, with the speed and cost of their mid-tier model, Claude 3 Sonnet."\r\n            "Strengths: Claude 3.5 Sonnet stands out with its ability to write, edit, and execute code effectively, making it a valuable tool for fixing bugs, migrating codebases, and handling complex coding problems. Compared to previous Claude models, Sonnet operates significantly faster, which is beneficial for tasks requiring quick turnaround times like customer support or dynamic content generation. The model demonstrates strong reasoning capabilities, allowing it to understand context and provide accurate solutions to complex problems. Sonnet is often considered a more cost-efficient option due to its faster processing speed and lower token costs compared to older Claude models. "\r\n            "Weaknesses: While proficient in many tasks, Claude 3.5 Sonnet may not be as adept at deep analytical tasks requiring a high level of nuance and complexity compared to older models like Claude 3 Opus. Compared to other AI models, Claude might lack advanced features in areas like image recognition or scientific research depending on the specific application. "\r\n        ),\r\n        max_tokens=4096,\r\n        benchmarks={\r\n            "MMLU": 0.887,\r\n            "GPQA": 0.594,\r\n            "HumanEval": 0.920,\r\n            "MATH": 0.711,\r\n            "BFCL": 0.902,\r\n            "MGSM": 0.916\r\n        },\r\n        cost_per_million_tokens=15.0, # Example cost in USD\r\n        latency=0.97        # Example: tokens per second\r\n    ),\r\n    "dall-e-3": {\r\n        name:"dall-e-3",\r\n        provider:"openai",\r\n        description:"OpenAI\'s most advanced image generation model"\r\n    },\r\n\r\n]\n'})}),"\n",(0,t.jsx)(n.h4,{id:"-supported-chat-models",children:"\ud83d\udccb Supported Chat Models"}),"\n",(0,t.jsx)(n.p,{children:"The Omni API aggregates several state-of-the-art chat models from multiple providers. Below is the list of all chat models currently supported:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"OpenAI Models:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"gpt-4"}),"\n",(0,t.jsx)(n.li,{children:"gpt-3.5-turbo"}),"\n",(0,t.jsx)(n.li,{children:"gpt-4o-mini"}),"\n",(0,t.jsx)(n.li,{children:"gpt-4o"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Anthropic Models:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"claude-3-opus"}),"\n",(0,t.jsx)(n.li,{children:"claude-3-5-sonnet"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"DeepSeek Models:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"deepseek-v3"}),"\n",(0,t.jsx)(n.li,{children:"deepseek-r1"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Gemini Models:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"gemini-2.0-flash"}),"\n",(0,t.jsx)(n.li,{children:"gemini-2.0-pro-exp-02-05"}),"\n",(0,t.jsx)(n.li,{children:"gemini-2.0-flash-thinking-exp-01-21"}),"\n",(0,t.jsx)(n.li,{children:"gemini-exp-1206"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Gemini Models:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"gemini-2.0-flash"}),"\n",(0,t.jsx)(n.li,{children:"gemini-2.0-pro-exp-02-05"}),"\n",(0,t.jsx)(n.li,{children:"gemini-2.0-flash-thinking-exp-01-21"}),"\n",(0,t.jsx)(n.li,{children:"gemini-exp-1206"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Together AI Models:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"meta-llama/Meta-Llama-3.3-70B-Instruct-Turbo"}),"\n",(0,t.jsx)(n.li,{children:"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"}),"\n",(0,t.jsx)(n.li,{children:"Qwen/Qwen2-VL-72B-Instruct"}),"\n",(0,t.jsx)(n.li,{children:"mistralai/Mistral-7B-Instruct-v0.2"}),"\n",(0,t.jsx)(n.li,{children:"microsoft/WizardLM-2-8x22B"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>o});var i=s(6540);const t={},r=i.createContext(t);function l(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);